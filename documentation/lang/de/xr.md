---
title: VR & AR (WebXR)
---

## Unterst√ºtzte Ger√§te

Needle Engine unterst√ºtzt die vollst√§ndige [WebXR-Spezifikation](https://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API), einschlie√ülich AR und VR. WebXR ist ein offizieller Webstandard, der immersive Erlebnisse ins Web bringt, mit allen Vorteilen des Webs: keine Installation, kein App Store, keine SDKs erforderlich.

Alle Ger√§te mit einem Browser k√∂nnen mit Needle erstellte Apps ausf√ºhren. Wenn der Browser WebXR unterst√ºtzt, funktionieren Ihre Apps automatisch auch in XR, indem sie unsere integrierten Komponenten verwenden. Dazu geh√∂ren Desktop-Browser, mobile Browser, viele Browser auf AR/VR-Headsets, aber auch andere aufkommende Technologien wie Looking Glass Displays, Smart Glasses und mehr.

:::tip App-freie iOS AR-Unterst√ºtzung √ºber USDZ/QuickLook
W√§hrend iOS-Ger√§te noch keine offizielle WebXR-Unterst√ºtzung bieten, unterst√ºtzt Needle die Erstellung von AR-Erlebnissen auf iOS mithilfe von [Everywhere Actions](everywhere-actions.md). Weitere Details finden Sie im [iOS-Abschnitt](#augmented-reality-and-webxr-on-ios). Sie k√∂nnen reichhaltige, interaktive Erlebnisse erstellen, die nahtlos in AR auf iOS-Ger√§ten funktionieren, selbst mit den Einschr√§nkungen, die Apple festgelegt hat.

Wenn Sie den AR-Modus auf iOS aufrufen, konvertiert Needle Ihre Szene automatisch in eine USDZ-Datei, die dann in AR mithilfe von Apples QuickLook angezeigt wird. Objekte, Materialien, Audio, Animation und Everywhere Actions bleiben erhalten.
:::

Die folgende Tabelle listet einige der Ger√§te auf, die wir erfolgreich mit Needle Engine getestet haben.
Wenn ein neues Ger√§t auf den Markt kommt, das WebXR unterst√ºtzt, funktioniert es ohne weiteres mit Ihren Apps. Dies ist einer der gro√üen Vorteile der Entwicklung mit dem Browser als Plattform ‚Äì die Kompatibilit√§t ist nicht auf eine bestimmte Gruppe von Ger√§ten oder SDKs beschr√§nkt.

| Headset Device | Browser | Notes |
| -- | -- | -- |
| Apple Vision Pro | ‚úîÔ∏è Safari | Hand-Tracking, Unterst√ºtzung f√ºr transienten Pointer |
| Meta Quest 3 | ‚úîÔ∏è Meta Browser | Hand-Tracking, Unterst√ºtzung f√ºr sessiongranted<sup>1</sup>, Passthrough, Tiefenmessung, Mesh-Tracking |
| Meta Quest 3S | ‚úîÔ∏è Meta Browser | Hand-Tracking, Unterst√ºtzung f√ºr sessiongranted<sup>1</sup>, Passthrough, Tiefenmessung, Mesh-Tracking |
| Meta Quest 2 | ‚úîÔ∏è Meta Browser | Hand-Tracking, Unterst√ºtzung f√ºr sessiongranted<sup>1</sup>, Passthrough (Schwarz-Wei√ü) |
| Meta Quest 1 | ‚úîÔ∏è Meta Browser | Hand-Tracking, Unterst√ºtzung f√ºr sessiongranted<sup>1</sup> |
| Meta Quest Pro | ‚úîÔ∏è Meta Browser | Hand-Tracking, Unterst√ºtzung f√ºr sessiongranted<sup>1</sup>, Passthrough |
| Pico Neo 4 | ‚úîÔ∏è Pico Browser | Passthrough, Hand-Tracking<sup>2</sup> |
| Pico Neo 3 | ‚úîÔ∏è Pico Browser | kein Hand-Tracking, invertierte Controller-Thumbsticks |
| Oculus Rift 1/2 | ‚úîÔ∏è Chrome |  |
| Valve Index | ‚úîÔ∏è Chrome |  |
| HTC Vive | ‚úîÔ∏è Chrome |  |
| Hololens 2 | ‚úîÔ∏è Edge | Hand-Tracking, Unterst√ºtzung f√ºr AR und VR (im VR-Modus wird der Hintergrund ebenfalls gerendert) |

| Mobile Device | Browser | Notes |
| -- | -- | -- |
| Android 10+ | ‚úîÔ∏è Chrome | |
| Android 10+ | ‚úîÔ∏è Firefox | |
| iOS 15+ | (‚úîÔ∏è)<sup>3</sup> Safari<br/>(‚úîÔ∏è)<sup>3</sup> Chrome | Keine vollst√§ndige Code-Unterst√ºtzung, aber Needle [Everywhere Actions](everywhere-actions.md) werden zur Erstellung dynamischer, interaktiver USDZ-Dateien unterst√ºtzt. |
| iOS 15+ | ‚úîÔ∏è WebXR Viewer | Browser ist inzwischen etwas veraltet |
| Hololens 2 | ‚úîÔ∏è Edge | |
| Hololens 1 | ‚ùå | keine WebXR-Unterst√ºtzung |
| Magic Leap 2 | ‚úîÔ∏è | |
| Magic Leap 1 | ‚úîÔ∏è | veraltetes Ger√§t |

| Other Devices | Browser | Notes |
| -- | -- | -- |
| Looking Glass Holographic Display | ‚úîÔ∏è Chrome | erfordert Looking Glass bridge und etwas eigenen Code, [siehe unser Beispiel](https://engine.needle.tools/samples/looking-glass/) |
| Logitech MX Ink | ‚úîÔ∏è Meta Browser | offiziell unterst√ºtzt, siehe [Dokumentation](https://logitech.github.io/mxink/WebXR/WebXrIntegration.html#using-needle-tools) |

<sup>1</sup>: Erfordert die Aktivierung eines Browser-Flags: `chrome://flags/#webxr-navigation-permission`
<sup>2</sup>: Erfordert die Aktivierung einer Einstellung in den Entwickleroptionen
<sup>3</sup>: Verwendet [Everywhere Actions](everywhere-actions.md) oder [andere Ans√§tze](#augmented-reality-and-webxr-on-ios)

## VR-, AR- und QuickLook-Beispiele

Besuchen Sie unsere [Needle Engine Samples](https://engine.needle.tools/samples/?overlay=samples&tag=xr), um viele interaktive Beispiele sofort auszuprobieren. Oder testen Sie es live auf Ihrem Ger√§t, indem Sie auf die Schaltfl√§chen <kbd>QR Code</kbd> (f√ºr Telefone) oder <kbd>Open on Quest</kbd> (f√ºr Meta Quest-Headsets) unten klicken.

<sample src="https://engine.needle.tools/samples/collaborative-sandbox/"/>

## Hinzuf√ºgen von VR- und AR-Funktionen zu einer Szene

AR-, VR- und Netzwerkf√§higkeiten in Needle Engine sind modular aufgebaut. Sie k√∂nnen w√§hlen, ob Sie keine davon unterst√ºtzen oder nur bestimmte Funktionen hinzuf√ºgen m√∂chten.

### Grundfunktionen

1.  **AR und VR aktivieren**
    F√ºgen Sie eine `WebXR`-Komponente hinzu.
    *Optional:* Sie k√∂nnen einen benutzerdefinierten Avatar festlegen, indem Sie auf ein [Avatar Prefab](#avatars) verweisen.
    Standardm√§√üig ist ein einfacher `DefaultAvatar` zugewiesen.

2.  **Teleportation aktivieren**
    F√ºgen Sie eine `TeleportTarget`-Komponente zu Objekthierarchien hinzu, auf die teleportiert werden kann.
    Um bestimmte Objekte auszuschlie√üen, setzen Sie deren Layer auf `IgnoreRaycasting`.

### Multiplayer

1.  **Networking aktivieren**
    F√ºgen Sie eine `SyncedRoom`-Komponente hinzu.

2.  **Desktop Viewer Sync aktivieren**
    F√ºgen Sie eine `SyncedCamera`-Komponente hinzu.

3.  **Voice Chat aktivieren**
    F√ºgen Sie eine `VoIP`-Komponente hinzu.

:::tip Szenenstruktur
Diese Komponenten k√∂nnen sich √ºberall in Ihrer Hierarchie befinden. Sie k√∂nnen auch alle auf demselben GameObject liegen, was ein √ºbliches Muster ist.
:::

> **[Castle Builder](https://castle.needle.tools/)** verwendet alle oben genannten Funktionen f√ºr ein plattform√ºbergreifendes Multiplayer-Sandbox-Erlebnis.
> ‚Äì #madebyneedle üíö

### Spezielle AR-Komponenten

1.  **AR-Session-Root und -Skalierung definieren**
    F√ºgen Sie Ihrem Root-Objekt eine `WebARSessionRoot`-Komponente hinzu. Bei AR-Erlebnissen m√∂chten Sie die Szene oft so skalieren, dass sie in die reale Welt passt.
2.  Definieren Sie die **Benutzerskala**, um den Benutzer beim Betreten von AR im Verh√§ltnis zur Szene zu verkleinern (< 1) oder zu vergr√∂√üern (> 1).

### Steuerung der Objektanzeige f√ºr XR

1.  **Definieren Sie, ob ein Objekt im Browser, in AR, in VR, in der First Person, in der Third Person sichtbar ist**
    F√ºgen Sie dem Objekt, das Sie steuern m√∂chten, eine `XR Flag`-Komponente hinzu.

2.  **√Ñndern Sie die Optionen im Dropdown** nach Bedarf.
    G√§ngige Anwendungsf√§lle sind
    - Ausblenden von B√∂den beim Betreten von AR
    - Ausblenden von Avatar-Teilen in der First oder Third Person Ansicht. In der First-Person-Ansicht sollte eine Person zum Beispiel ihr eigenes Kopfmodell nicht sehen k√∂nnen.

### Reisen zwischen VR-Welten

Needle Engine unterst√ºtzt den [`sessiongranted`](https://github.com/immersive-web/navigation)-Zustand. Dies erm√∂glicht Benutzern, nahtlos zwischen WebXR-Anwendungen zu wechseln, ohne eine immersive Sitzung zu verlassen ‚Äì sie bleiben in VR oder AR.

Derzeit wird dies nur auf Oculus Quest 1, 2 und 3 im Oculus Browser unterst√ºtzt. Auf anderen Plattformen werden Benutzer aus ihrer aktuellen immersiven Sitzung geworfen und m√ºssen auf der neuen Seite VR erneut betreten.
Erfordert die Aktivierung eines Browser-Flags: `chrome://flags/#webxr-navigation-permission`

-   **Klicken Sie auf Objekte, um Links zu √∂ffnen**
    F√ºgen Sie die `OpenURL`-Komponente hinzu, die es sehr einfach macht, verbundene Welten zu erstellen.

## Scripting

Lesen Sie mehr √ºber Scripting f√ºr XR in der [XR-Scripting-Dokumentation](./scripting.md#xr-event-methods)

## Avatare

Auch wenn wir derzeit keine sofort einsatzbereite Integration externer Avatarsysteme anbieten, k√∂nnen Sie anwendungsspezifische Avatare oder benutzerdefinierte Systeme erstellen.

-   **Einen benutzerdefinierten Avatar erstellen**
    -   Erstellen Sie ein leeres GameObject als Avatar-Wurzel
    -   F√ºgen Sie ein Objekt mit dem Namen `Head` hinzu und f√ºgen Sie eine `XRFlag` hinzu, die auf Third Person eingestellt ist
    -   F√ºgen Sie Objekte mit den Namen `HandLeft` und `HandRight` hinzu
    -   F√ºgen Sie Ihre Grafiken unterhalb dieser Objekte hinzu.

### Experimentelle Avatar-Komponenten

Es gibt eine Reihe experimenteller Komponenten, um ausdrucksst√§rkere Avatare zu erstellen. Zu diesem Zeitpunkt empfehlen wir, sie zu duplizieren, um eigene Varianten zu erstellen, da sie sp√§ter ge√§ndert oder entfernt werden k√∂nnten.

![20220817-230858-87dG-Unity_PLjQ](https://user-images.githubusercontent.com/2693840/185243523-57c4b2a9-0ec7-4f88-b53b-585e879d504d.gif)
*Beispiel Avatar Rig mit einfachem Halsmodell und Gliedma√üen-Constraints*

-   **Zuf√§llige Spielerfarben**
    Als Beispiel f√ºr die Avatar-Anpassung k√∂nnen Sie eine `PlayerColor`-Komponente zu Ihren Renderern hinzuf√ºgen.
    Diese zuf√§llige Farbe wird zwischen den Spielern synchronisiert.

-   **Augenrotation**
    `AvatarEyeLook_Rotation` dreht GameObjects (Augen), um anderen Avataren und einem zuf√§lligen Ziel zu folgen. Diese Komponente wird zwischen den Spielern synchronisiert.

-   **Augenblinzeln**
    `AvatarBlink_Simple` versteckt GameObjects (Augen) zuf√§llig alle paar Sekunden und imitiert so ein Blinzeln.

![image](https://user-images.githubusercontent.com/2693840/185233753-e6de49f0-31c3-4851-9919-551309303ebd.png)
*Beispiel Avatar Prefab Hierarchie*

-   **Offset Constraint**
    `OffsetConstraint` erm√∂glicht das Verschieben eines Objekts im Verh√§ltnis zu einem anderen im Avatar-Raum. Dies erm√∂glicht es beispielsweise, dass ein Body dem Head folgt, aber die Rotation ausgerichtet bleibt. Es erm√∂glicht auch den Aufbau einfacher Halsmodelle.

-   **Limb Constraint**
    `BasicIKConstraint` ist ein sehr minimalistisches Constraint, das zwei Transforms und einen Hinweis ben√∂tigt. Dies ist n√ºtzlich, um einfache Arm- oder Beinketten zu konstruieren. Da die Rotation derzeit nicht richtig implementiert ist, m√ºssen Arme und Beine m√∂glicherweise rotationssymmetrisch sein, damit sie "richtig aussehen". Es hei√üt aus gutem Grund "Basic"!

## HTML-Inhalts-Overlays in AR

Wenn Sie unterschiedliche HTML-Inhalte anzeigen m√∂chten, je nachdem, ob der Client einen regul√§ren Browser oder AR oder VR verwendet, k√∂nnen Sie einfach eine Reihe von HTML-Klassen verwenden.
Dies wird √ºber HTML-Elementklassen gesteuert. Um Inhalte beispielsweise auf dem Desktop und in AR erscheinen zu lassen, f√ºgen Sie ein ``<div class="desktop ar"> ... </div>`` innerhalb des `<needle-engine>`-Tags hinzu:

```html
<needle-engine>
    <div class="desktop ar" style="pointer-events:none;">
        <div class="positioning-container">
          <p>Ihr Inhalt f√ºr AR und Desktop kommt hier rein</p>
          <p class="only-in-ar">Dies wird nur in AR sichtbar sein</p>
        <div>
    </div>
</needle-engine>
```

Inhalts-Overlays werden mithilfe der optionalen `dom-overlay`-Funktion implementiert, die normalerweise auf bildschirmbasierten AR-Ger√§ten (Telefone, Tablets) unterst√ºtzt wird.

Verwenden Sie die Klasse `.ar-session-active`, um spezifische Inhalte w√§hrend der AR-Sitzung ein-/auszublenden. Die Pseudoklasse [`:xr-overlay`](https://www.w3.org/TR/webxr-dom-overlays-1/#css-pseudo-class) sollte derzeit nicht verwendet werden, da ihre Verwendung den WebXR Viewer von Mozilla besch√§digt.

```css
.only-in-ar {
  display: none;
}

.ar-session-active .only-in-ar {
  display:initial;
}
```

Es ist erw√§hnenswert, dass das Overlay-Element [w√§hrend der XR-Sitzung immer im Vollbildmodus angezeigt wird](https://www.w3.org/TR/webxr-dom-overlays-1/#ua-style-sheet-defaults), unabh√§ngig von angewendeten Stildefinitionen. Wenn Sie Elemente anders ausrichten m√∂chten, sollten Sie einen Container _innerhalb_ des Elements mit der Klasse `class="ar"` erstellen.

<sample src="https://engine.needle.tools/samples-uploads/ar-overlay/"/>

## Augmented Reality und WebXR auf iOS

Augmented Reality-Erlebnisse auf iOS sind etwas eingeschr√§nkt, da Apple WebXR derzeit auf iOS-Ger√§ten nicht unterst√ºtzt.

Needle Engine's [Everywhere Actions](everywhere-actions.md) wurden entwickelt, um diese L√ºcke zu schlie√üen und automatische interaktive Funktionen auf iOS-Ger√§ten f√ºr Szenen zu erm√∂glichen, die aus spezifischen Komponenten bestehen. Sie unterst√ºtzen eine Teilmenge der Funktionalit√§t, die in WebXR verf√ºgbar ist, zum Beispiel r√§umliches Audio, Bild-Tracking, Animationen und mehr. Weitere Informationen finden Sie in [der Dokumentation](everywhere-actions.md).

:::tip Begrenzte Unterst√ºtzung f√ºr benutzerdefinierten Code in QuickLook
Apple hat starke Einschr√§nkungen hinsichtlich der Art von Inhalten festgelegt, die in QuickLook verwendet werden k√∂nnen. Daher k√∂nnen benutzerdefinierte Skriptkomponenten nicht automatisch f√ºr die Verwendung in AR auf iOS konvertiert werden. Sie k√∂nnen mithilfe unserer Everywhere Actions API Unterst√ºtzung f√ºr einige Arten von benutzerdefiniertem Code hinzuf√ºgen.
:::

### Musikinstrument ‚Äì WebXR- und QuickLook-Unterst√ºtzung

Hier ist ein Beispiel f√ºr ein Musikinstrument, das Everywhere Actions verwendet und daher in Browsern und in AR auf iOS-Ger√§ten funktioniert.
Es verwendet r√§umliches Audio, Animation und Tap-Interaktionen.
<sample src="https://engine.needle.tools/samples-uploads/musical-instrument" />

### Everywhere Actions und andere Optionen f√ºr iOS AR

Es gibt auch andere Optionen, um iOS-Benutzer zu noch leistungsf√§higeren interaktiven AR-Erlebnissen zu f√ºhren:

3.  **On-the-fly-Export von Inhalten als USDZ-Dateien.**
    Diese Dateien k√∂nnen auf iOS-Ger√§ten in AR angezeigt werden. Beim Export aus Szenen mit Everywhere Actions ist die Interaktivit√§t dieselbe, mehr als ausreichend f√ºr Produktkonfiguratoren, narrative Erlebnisse und √Ñhnliches.
    Ein Beispiel ist [Castle Builder](https://castle.needle.tools), wo Kreationen (nicht die Live-Sitzung) in AR betrachtet werden k√∂nnen.

> **[Encryption in Space](https://accurate-tree-observation.glitch.me/)** verwendet diesen Ansatz. Spieler k√∂nnen kollaborativ Text in die Szene auf ihren Bildschirmen platzieren und dann die Ergebnisse in AR auf iOS ansehen. Auf Android k√∂nnen sie auch direkt in WebXR interagieren.
> ‚Äì #madewithneedle von Katja Rempel üíö

1.  **F√ºhren von Benutzern zu WebXR-kompatiblen Browsern auf iOS.**
    Je nach Zielgruppe k√∂nnen Sie Benutzer auf iOS beispielsweise zum [WebXR Viewer](https://apps.apple.com/de/app/webxr-viewer/id1295998056) von Mozilla f√ºhren, um AR auf iOS zu erleben.

2.  **Verwendung des Kamerazugriffs und benutzerdefinierter Algorithmen auf iOS-Ger√§ten.**
    Man kann den Zugriff auf das Kamerabild anfordern und benutzerdefinierte Algorithmen ausf√ºhren, um die Ger√§teposition zu bestimmen.
    Obwohl wir derzeit keine integrierten Komponenten daf√ºr bereitstellen, finden Sie hier einige Verweise auf Bibliotheken und Frameworks, die wir in Zukunft ausprobieren m√∂chten:
    -   [AR.js](https://github.com/AR-js-org/AR.js) (Open Source)
        -   [Experimentelle AR.js-Integration](https://github.com/FireDragonGameStudio/NeedleAndARjs) von FireDragonGameStudio
    -   [Mind AR](https://github.com/hiukim/mind-ar-js) (Open Source)
    -   [8th Wall](https://www.8thwall.com/) (kommerziell)

## Bild-Tracking

Needle Engine unterst√ºtzt **WebXR Image Tracking** ([Live Demo](https://engine.needle.tools/samples/image-tracking?utm_source=docs&utm_content=xr)) auf Android und **QuickLook Image Tracking** auf iOS.

Zus√§tzliche Dokumentation finden Sie im Abschnitt [Everywhere Actions](everywhere-actions.md#image-tracking).

:::warning WebXR Image Tracking befindet sich noch in einer "Draft"-Phase und ist nicht allgemein verf√ºgbar
Bislang konnten sich die Browser-Anbieter noch nicht auf die endg√ºltige Image Tracking API f√ºr WebXR einigen. Solange die Spezifikation in der "Draft"-Phase ist ([Marker Tracking Explainer](https://github.com/immersive-web/marker-tracking/blob/main/explainer.md)),
m√ºssen Sie und die Benutzer Ihrer App die folgenden Schritte ausf√ºhren, um WebXR ImageTracking auf Android-Ger√§ten zu aktivieren:
1. Besuchen Sie ``chrome://flags`` in Ihrem Android Chrome-Browser
2. Suchen und aktivieren Sie die Option `WebXR Incubations`
:::

Ohne diese Spezifikation kann man immer noch den Zugriff auf das Kamerabild anfordern und benutzerdefinierte Algorithmen ausf√ºhren, um die Ger√§teposition zu bestimmen. Der Nachteil ist, dass Benutzer zus√§tzliche Berechtigungen wie Kamerazugriff akzeptieren m√ºssen und das Tracking nicht so genau sein wird wie mit den nativen F√§higkeiten des Ger√§ts.

Hier sind einige Bibliotheken, um Bild-Tracking basierend auf Kamerazugriff und lokalen Computer-Vision-Algorithmen hinzuzuf√ºgen:
-   [Experimentelle AR.js-Integration mit Needle Engine](https://github.com/FireDragonGameStudio/NeedleAndARjs) von FireDragonGameStudio
-   [AR.js](https://github.com/AR-js-org/AR.js) (Open Source)
-   [Mind AR](https://github.com/hiukim/mind-ar-js) (Open Source)

## Referenzen

[WebXR Device API](https://www.w3.org/TR/webxr/)
[caniuse: WebXR](https://caniuse.com/webxr)
[Apples vorl√§ufige USD-Verhaltensweisen](https://developer.apple.com/augmented-reality/quick-look/)

Seite automatisch mit KI √ºbersetzt